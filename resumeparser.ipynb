{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n12qcwe2fuZ5",
        "outputId": "5d79c4de-c700-443d-9b4b-283c1bfa3c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jason Miller\n",
            "Amazon Associate\n",
            "\n",
            "Los Angeles\n",
            "3868683442\n",
            "\n",
            "Experienced Amazon Associate with five years tenure in a shipping yard setting maintaining an average pickingpacking speed of 98 Holds a zero error score in adhering to packing specs and 97 errorfree ratio on packing records Completed a certificate in Warehouse Sanitation and has a valid commercial drivers license\n",
            "\n",
            "PERSONAL INFORMATION\n",
            "  Address 1515 Pacific Ave Los Angeles CA 90291\n",
            "  Nationality \n",
            "  Driving License Full\n",
            "  Hobbies Action Cricket Rugby Athletics\n",
            "\n",
            "SOCIAL PROFILES\n",
            "   LinkedIn \n",
            "   Pinterest \n",
            "   Resume Templates \n",
            "   Build this template \n",
            "\n",
            "LANGUAGES\n",
            "   English\n",
            "   Spanish\n",
            "\n",
            "SKILLS\n",
            "   Cleaning Equipment\n",
            "   Cleaning Equipment\n",
            "   Mathematics\n",
            "   Cleaning Equipment\n",
            "   Deep Sanitation Practices\n",
            "\n",
            "WORK EXPERIENCE\n",
            "   January 2021  July 2022\n",
            "    Amazon Warehouse Associate at Amazon Miami Gardens\n",
            "      Performed all warehouse laborer duties such as packing picking counting record keeping and maintaining a clean area\n",
            "\n",
            "  Consistently maintained pickingpacking speeds in the 98th percentile\n",
            "  Picked all orders with 100 accuracy despite high speeds\n",
            "  Maintained a clean work area meeting 975 of the inspection requirements\n",
            "\n",
            "\n",
            "   January 2019  December 2020\n",
            "    Laboratory Inventory Assistant  at  Dunrea Laboratories Orlando\n",
            "      Fulltime lab assistant in a small regional laboratory tasked with  participating in Kaizen Events Gemba walks and 5S to remove barriers and improve productivity\n",
            "\n",
            "  Filled the warehouse helper job description which involved picking packing shipping inventory management and cleaning equipment\n",
            "  Saved 12 on UPS orders by staying on top of special deals\n",
            "  Cut down storage waste by 23 by switching to a Kanban system\n",
            "\n",
            "\n",
            "\n",
            "EDUCATION\n",
            "   January 2021  July 2022\n",
            "    Atlanta Technical College Atlanta Associates Degree in Logistics and Supply Chain Fundamentals\n",
            "\n",
            "    \n",
            "  Majors Warehousing Operations Logistics and Distribution Practices\n",
            "  Minors Inventory Systems Supply Chain Principles\n",
            "\n",
            "\n",
            "COURSES\n",
            "   July 2022  July 2022\n",
            "    Online Graduate Certificate in Warehousing  Supply Chain Management Southern New Hampshire University SNHU NH\n",
            "   January 2021  May 2021\n",
            "    Warehousing Operations and Disposal Course Graduate School USA Washington DC\n",
            "\n",
            "ACHIEVEMENTS\n",
            "     \n",
            "\n",
            "    \n",
            "  Decrease the errors rate and QC several more orders that we ship per day\n",
            "  Awarded Employee of the month due to consistent attendance punctuality and performance\n",
            "  Managed workflow of associates for the FC\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def extract_text_from_resume(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        resume_text = file.read()\n",
        "\n",
        "    # Remove URLs\n",
        "    cleaned_text = re.sub(r'http\\S+', '', resume_text)\n",
        "\n",
        "    # Remove non-alphanumeric characters except spaces and line breaks\n",
        "    cleaned_text = re.sub(r'[^\\w\\s\\n]', '', cleaned_text)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "file_path = 'Text-Resume-Amazon-Associate.txt'\n",
        "\n",
        "#cleaned text\n",
        "cleaned_resume_text = extract_text_from_resume(file_path)\n",
        "\n",
        "print(cleaned_resume_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to read text from a text file\n",
        "def read_text_from_txt(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return \"\"\n",
        "\n",
        "# Education\n",
        "def extract_education(text):\n",
        "    lines = text.split('\\n')\n",
        "    education_info = []\n",
        "    is_education_section = False\n",
        "\n",
        "    for line in lines:\n",
        "        if \"EDUCATION\" in line:\n",
        "            is_education_section = True\n",
        "            continue\n",
        "        elif \"SKILLS\" in line:\n",
        "            is_education_section = False\n",
        "\n",
        "        if is_education_section and line.strip():\n",
        "            education_info.append(line.strip())\n",
        "\n",
        "    return education_info\n",
        "\n",
        "def extract_education_degrees(education_info):\n",
        "    degree_keywords = [\"bsc\", \"msc\", \"btech\", \"mtech\", \"be\", \"me\", \"bachelor\", \"master\", \"degree\"]\n",
        "    education_degrees = []\n",
        "\n",
        "    for line in education_info:\n",
        "        lower_line = line.lower()\n",
        "        if any(keyword in lower_line for keyword in degree_keywords):\n",
        "            education_degrees.append(line)\n",
        "\n",
        "    return education_degrees\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    education_info = extract_education(resume_text)\n",
        "    education_degrees = extract_education_degrees(education_info)\n",
        "\n",
        "    if education_degrees:\n",
        "        print(\"Extracted Education Degrees:\")\n",
        "        for degree in education_degrees:\n",
        "            print(degree)\n",
        "    else:\n",
        "        print(\"No education degrees found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RehPiQAIiCVC",
        "outputId": "44510726-ddc7-4b66-84ee-dc4d566488e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Education Degrees:\n",
            "BTECH Computer Science Engineering Core\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def read_text_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def extract_achievements(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    achievement_keywords = [\"achieve\", \"accomplish\", \"award\", \"recognition\", \"win\", \"success\"]\n",
        "\n",
        "    achievements = []\n",
        "    for sentence in sentences:\n",
        "        for keyword in achievement_keywords:\n",
        "            if keyword in sentence.lower():\n",
        "                achievements.append(sentence)\n",
        "                break\n",
        "\n",
        "    return achievements\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "\n",
        "    achievements = extract_achievements(resume_text)\n",
        "\n",
        "    print(\"Achievements:\")\n",
        "    for achievement in achievements:\n",
        "        print(achievement)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc9DMKdqjapp",
        "outputId": "4d26e93b-e991-48b7-df56-19af06490536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Achievements:\n",
            "Accomplished projects include Resume Parsing with NLTK and\n",
            "collaborative filtering for recommendation systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NAME\n",
        "\n",
        "import re\n",
        "\n",
        "def read_text_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def extract_name(text):\n",
        "    #assuming two words\n",
        "    name_pattern = r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b'\n",
        "    name_matches = re.findall(name_pattern, text)\n",
        "    return name_matches[0] if name_matches else None\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    name = extract_name(resume_text)\n",
        "\n",
        "    if name:\n",
        "        print(f\"Extracted Name: {name}\")\n",
        "    else:\n",
        "        print(\"No name found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tqdo8HkjjQY",
        "outputId": "77071b65-7353-4081-9d96-d6bde4de63e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Name: Sampreeta Subhakanshi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Email\n",
        "\n",
        "import re\n",
        "\n",
        "def read_text_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def extract_email_addresses(text):\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    email_addresses = re.findall(email_pattern, text, re.IGNORECASE)\n",
        "    return email_addresses\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "\n",
        "    email_addresses = extract_email_addresses(resume_text)\n",
        "\n",
        "    if email_addresses:\n",
        "        print(\"Email Addresses:\")\n",
        "        for email in email_addresses:\n",
        "            print(email)\n",
        "    else:\n",
        "        print(\"No email addresses found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_npMXd-kQwI",
        "outputId": "18a2199d-c624-49eb-8aac-e2250a559945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email Addresses:\n",
            "sampreeta2004@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Skills\n",
        "\n",
        "def extract_skills(text):\n",
        "    lines = text.split('\\n')\n",
        "    skills_info = []\n",
        "    is_skills_section = False\n",
        "\n",
        "    for line in lines:\n",
        "        if \"SKILLS\" in line:\n",
        "            is_skills_section = True\n",
        "            continue\n",
        "        elif \"WORK EXPERIENCE\" in line:\n",
        "            is_skills_section = False\n",
        "\n",
        "        if is_skills_section and line.strip():\n",
        "            skills_info.append(line.strip())\n",
        "\n",
        "    return skills_info\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    skills_info = extract_skills(resume_text)\n",
        "\n",
        "    if skills_info:\n",
        "        print(\"Extracted Skills:\")\n",
        "        for skill in skills_info:\n",
        "            print(skill)\n",
        "    else:\n",
        "        print(\"No skills information found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5yur8bUlym3",
        "outputId": "d670a55a-ee78-480a-fe1b-4befaa6c7d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Skills:\n",
            "Python, R, Java, NumPy, pandas, SQL , NLTK , MATLAB, Cloud Computing , Kali Linux, Microsoft Office (Excel, Word, PowerPoint), Content Writing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linkedin\n",
        "\n",
        "import re\n",
        "\n",
        "def read_text_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def extract_linkedin_urls(text):\n",
        "    linkedin_pattern = r'linkedin\\.com\\/in\\/[a-zA-Z0-9-]+'\n",
        "    linkedin_urls = re.findall(linkedin_pattern, text, re.IGNORECASE)\n",
        "    return linkedin_urls\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    linkedin_urls = extract_linkedin_urls(resume_text)\n",
        "\n",
        "    if linkedin_urls:\n",
        "        print(\"LinkedIn Profile URLs:\")\n",
        "        for url in linkedin_urls:\n",
        "            print(f\"LinkedIn: {url}\")\n",
        "    else:\n",
        "        print(\"No LinkedIn Profile URLs found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcmZoHxNl3mt",
        "outputId": "d7579559-facf-4e27-f16c-d2544f2aa45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinkedIn Profile URLs:\n",
            "LinkedIn: linkedin.com/in/sampreetas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROJECT\n",
        "\n",
        "def extract_project_experience(text):\n",
        "    lines = text.split('\\n')\n",
        "    project_experience = []\n",
        "    is_project_section = False\n",
        "\n",
        "    for line in lines:\n",
        "        if \"PROJECT EXPERIENCE\" in line:\n",
        "            is_project_section = True\n",
        "            continue\n",
        "        elif \"LANGUAGES\" in line:\n",
        "            is_project_section = False\n",
        "\n",
        "        if is_project_section and line.strip():\n",
        "            project_experience.append(line.strip())\n",
        "\n",
        "    return project_experience\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    project_experience_info = extract_project_experience(resume_text)\n",
        "\n",
        "    if project_experience_info:\n",
        "        print(\"Extracted Project Experience:\")\n",
        "        for info in project_experience_info:\n",
        "            print(info)\n",
        "    else:\n",
        "        print(\"No project experience information found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQoHgtU7mfOi",
        "outputId": "7d7a0d7c-1a40-473b-a3fb-498baec6a252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Project Experience:\n",
            "CSM Technologies\n",
            "Resume Parser Using Natural Language Processing\n",
            "Bhubaneswar, Odisha\n",
            "Aug 2023 - Sep 2023\n",
            "Developed a resume parsing tool using machine learning and natural language processing techniques to extract key information from resumes.\n",
            "Vellore Institute of Technology\n",
            "Vellore, Tamil Nadu\n",
            "Security Enhancement through Microsoft Threat Mode\n",
            "Apr 2023 - May 2023\n",
            "Conducted comprehensive threat modeling exercises using the Microsoft Threat Modeling Tool for multiple software application\n",
            "Vellore Institute of Technology\n",
            "Vellore, Tamil Nadu\n",
            "Web Security Enhancement using Mozilla Observatory\n",
            "May 2023 - Jun 2023\n",
            "Utilized Mozilla Observatory to perform in-depth security scans on a diverse range of web applications.\n",
            "Vellore Institute of Technology\n",
            "Vellore, Tamil Nadu\n",
            "Vulnerability Mitigation using Metasploit\n",
            "Jun 2023 - Jul 2023\n",
            "Utilized Metasploit to perform penetration testing and exploit known vulnerabilities in controlled environments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Work experience\n",
        "\n",
        "def extract_work_experience(text):\n",
        "    lines = text.split('\\n')\n",
        "    work_experience = []\n",
        "    is_work_experience_section = False\n",
        "\n",
        "    for line in lines:\n",
        "        if \"WORK EXPERIENCE\" in line:\n",
        "            is_work_experience_section = True\n",
        "            continue\n",
        "        elif \"PROJECT EXPERIENCE\" in line:\n",
        "            is_work_experience_section = False\n",
        "\n",
        "        if is_work_experience_section and line.strip():\n",
        "            work_experience.append(line.strip())\n",
        "\n",
        "    return work_experience\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    work_experience_info = extract_work_experience(resume_text)\n",
        "\n",
        "    if work_experience_info:\n",
        "        print(\"Extracted Work Experience:\")\n",
        "        for info in work_experience_info:\n",
        "            print(info)\n",
        "    else:\n",
        "        print(\"No work experience information found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgnR10VqmftQ",
        "outputId": "11839fbe-b7df-4508-fc34-52347918ea6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Work Experience:\n",
            "CSM Technologies\n",
            "Intern\n",
            "Bhubaneswar, Odisha\n",
            "Aug 2023 - Present\n",
            "Collaborated on developing a resume parser using machine learning. Applied Python programming to build and implement the machine learning model. Utilised libraries such as spacy\n",
            "and numpy for model development, employed natural language processing techniques to extract relevant information from resumes.Engineered and optimised a model for accurate\n",
            "resume information extraction.\n",
            "IET( Institution of Engineering and Technology )\n",
            "CORE COMMITTEE MEMBER\n",
            "Vellore, Tamil Nadu\n",
            "Mar 2022 - Present\n",
            "Coordinated activities and communicated information among board, external auditors and management. Collaborated with fellow committee members to organize and execute various\n",
            "technical events, workshops, and seminars, aimed at promoting learning and knowledge sharing.\n",
            "IIT Patna\n",
            "Intern\n",
            "Patna , Bihar\n",
            "Aug 2021 - Sep 2021\n",
            "Led annotation efforts for large-scale data projects, providing high-quality and accurate annotations for machine learning and artificial intelligence models. Contributed to the creation\n",
            "and maintenance of annotation guidelines and documentation, ensuring consistency and alignment across annotation tasks.\n",
            "Siaraa Technologies\n",
            "Intern\n",
            "New Jersey, US\n",
            "Aug 2021 - Sep 2021\n",
            "Authored a series of informative blog posts on deploying Passwordless Authentication solutions, explaining various implementation approaches and their benefits. Developed content\n",
            "on proactive measures to prevent, detect, and respond to Ransomware Attacks, including effective incident response strategies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predefined_skills = [\"Python\", \"R\", \"Java\", \"NumPy\", \"pandas\", \"SQL\", \"NLTK\", \"MATLAB\", \"Cloud Computing\", \"Kali Linux\", \"Microsoft Office (Excel, Word, PowerPoint)\", \"Content Writing\"]\n",
        "\n",
        "# Extract skills\n",
        "def extract_skills_from_list(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "    skills_found = []\n",
        "\n",
        "    for word in words:\n",
        "        # Check if the word is in the predefined_skills list\n",
        "        if word in predefined_skills:\n",
        "            skills_found.append(word)\n",
        "\n",
        "    return skills_found\n",
        "\n",
        "# Read text from TXT file\n",
        "def read_text_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def main():\n",
        "    txt_file_path = 'samres.txt'\n",
        "\n",
        "    resume_text = read_text_from_txt(txt_file_path)\n",
        "    skills_found = extract_skills_from_list(resume_text)\n",
        "\n",
        "    if skills_found:\n",
        "        print(\"Extracted Skills:\")\n",
        "        for skill in skills_found:\n",
        "            print(skill)\n",
        "    else:\n",
        "        print(\"No predefined skills found in the text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc-8APqqmlSe",
        "outputId": "2e9a34d4-a30c-4fd5-884f-b64018290c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Skills:\n",
            "Python\n",
            "NLTK\n",
            "SQL\n",
            "NLTK\n",
            "Python\n"
          ]
        }
      ]
    }
  ]
}